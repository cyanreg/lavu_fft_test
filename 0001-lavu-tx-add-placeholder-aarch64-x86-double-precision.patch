From 409b0a09084e81e8800988f624e67fc9c4083008 Mon Sep 17 00:00:00 2001
From: Lynne <dev@lynne.ee>
Date: Thu, 18 Mar 2021 14:13:24 +0100
Subject: [PATCH] lavu/tx: add placeholder aarch64/x86 double-precision
 optimizations

---
 libavutil/aarch64/Makefile         |   4 +-
 libavutil/aarch64/tx_double_init.c | 198 +++++++++++++++++++++++++++++
 libavutil/aarch64/tx_double_neon.S |  26 ++++
 libavutil/tx.c                     |  60 +++++++++
 libavutil/tx.h                     |   8 +-
 libavutil/tx_priv.h                |  42 +++++-
 libavutil/tx_template.c            |   9 +-
 libavutil/x86/Makefile             |   2 +
 libavutil/x86/tx_double.asm        |  60 +++++++++
 libavutil/x86/tx_double_init.c     | 198 +++++++++++++++++++++++++++++
 10 files changed, 598 insertions(+), 9 deletions(-)
 create mode 100644 libavutil/aarch64/tx_double_init.c
 create mode 100644 libavutil/aarch64/tx_double_neon.S
 create mode 100644 libavutil/x86/tx_double.asm
 create mode 100644 libavutil/x86/tx_double_init.c

diff --git a/libavutil/aarch64/Makefile b/libavutil/aarch64/Makefile
index 5613813ba8..472593b200 100644
--- a/libavutil/aarch64/Makefile
+++ b/libavutil/aarch64/Makefile
@@ -1,4 +1,6 @@
 OBJS += aarch64/cpu.o                                                 \
         aarch64/float_dsp_init.o                                      \
+        aarch64/tx_double_init.o                                      \
 
-NEON-OBJS += aarch64/float_dsp_neon.o
+NEON-OBJS += aarch64/float_dsp_neon.o                                 \
+             aarch64/tx_double_neon.o                                 \
diff --git a/libavutil/aarch64/tx_double_init.c b/libavutil/aarch64/tx_double_init.c
new file mode 100644
index 0000000000..e6d147a16e
--- /dev/null
+++ b/libavutil/aarch64/tx_double_init.c
@@ -0,0 +1,198 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#define TX_DOUBLE
+#include "libavutil/tx_priv.h"
+#include "libavutil/aarch64/cpu.h"
+
+void ff_fft8_double_neon(AVTXContext *s, void *out, void *in, ptrdiff_t stride);
+
+
+#include <float.h>
+static void fft8(FFTComplex *z)
+{
+    FFTSample r1 = z[0].re - z[4].re;
+    FFTSample r2 = z[0].im - z[4].im;
+    FFTSample r3 = z[1].re - z[5].re;
+    FFTSample r4 = z[1].im - z[5].im;
+
+    FFTSample r5 = z[2].re - z[6].re;
+    FFTSample r6 = z[2].im - z[6].im;
+    FFTSample r7 = z[3].re - z[7].re;
+    FFTSample r8 = z[3].im - z[7].im;
+
+    FFTSample q1 = z[0].re + z[4].re;
+    FFTSample q2 = z[0].im + z[4].im;
+    FFTSample q3 = z[1].re + z[5].re;
+    FFTSample q4 = z[1].im + z[5].im;
+
+    FFTSample q5 = z[2].re + z[6].re;
+    FFTSample q6 = z[2].im + z[6].im;
+    FFTSample q7 = z[3].re + z[7].re;
+    FFTSample q8 = z[3].im + z[7].im;
+
+    FFTSample s3 = q1 - q3;
+    FFTSample s1 = q1 + q3;
+    FFTSample s4 = q2 - q4;
+    FFTSample s2 = q2 + q4;
+
+    FFTSample s7 = q5 - q7;
+    FFTSample s5 = q5 + q7;
+    FFTSample s8 = q6 - q8;
+    FFTSample s6 = q6 + q8;
+
+    FFTSample e1 = s1 * -1;
+    FFTSample e2 = s2 * -1;
+    FFTSample e3 = s3 * -1;
+    FFTSample e4 = s4 * -1;
+
+    FFTSample e5 = s5 *  1;
+    FFTSample e6 = s6 *  1;
+    FFTSample e7 = s7 * -1;
+    FFTSample e8 = s8 *  1;
+
+    FFTSample w1 =  e5 - e1;
+    FFTSample w2 =  e6 - e2;
+    FFTSample w3 =  e8 - e3;
+    FFTSample w4 =  e7 - e4;
+
+    FFTSample w5 =  s1 - e5;
+    FFTSample w6 =  s2 - e6;
+    FFTSample w7 =  s3 - e8;
+    FFTSample w8 =  s4 - e7;
+
+    z[0].re = w1;
+    z[0].im = w2;
+    z[2].re = w3;
+    z[2].im = w4;
+    z[4].re = w5;
+    z[4].im = w6;
+    z[6].re = w7;
+    z[6].im = w8;
+
+    FFTSample z1 = r1 - r4;
+    FFTSample z2 = r1 + r4;
+    FFTSample z3 = r3 - r2;
+    FFTSample z4 = r3 + r2;
+
+    FFTSample z5 = r5 - r6;
+    FFTSample z6 = r5 + r6;
+    FFTSample z7 = r7 - r8;
+    FFTSample z8 = r7 + r8;
+
+    z3 *= -1;
+    z5 *= -M_SQRT1_2;
+    z6 *= -M_SQRT1_2;
+    z7 *=  M_SQRT1_2;
+    z8 *=  M_SQRT1_2;
+
+    FFTSample t5 = z7 - z6;
+    FFTSample t6 = z8 + z5;
+    FFTSample t7 = z8 - z5;
+    FFTSample t8 = z7 + z6;
+
+    FFTSample u1 =  z2 + t5;
+    FFTSample u2 =  z3 + t6;
+    FFTSample u3 =  z1 - t7;
+    FFTSample u4 =  z4 + t8;
+
+    FFTSample u5 =  z2 - t5;
+    FFTSample u6 =  z3 - t6;
+    FFTSample u7 =  z1 + t7;
+    FFTSample u8 =  z4 - t8;
+
+    z[1].re = u1;
+    z[1].im = u2;
+    z[3].re = u3;
+    z[3].im = u4;
+    z[5].re = u5;
+    z[5].im = u6;
+    z[7].re = u7;
+    z[7].im = u8;
+}
+
+static av_unused void test_fft(AVTXContext *s, void *_out, void *_in,
+                               ptrdiff_t stride)
+{
+    FFTComplex *in = _in;
+    FFTComplex *out = _out;
+
+    FFTComplex *temp = av_malloc(2 * s->m * sizeof(FFTComplex)), *orig = temp;
+    for (int i = 0; i < s->m; i++) {
+        temp[i] = in[i];
+        out[i] = in[s->revtab[i]];
+    }
+
+    fft8(out);
+
+    ff_fft8_double_neon(s, temp, temp, stride);
+
+#if 1
+    temp += 0; out += temp - orig;
+
+    FFTComplex *ptr = (void *)out;
+
+    printf("\nIDX =      0re      0im      1re      1im      2re      2im      3re      3im\n"
+             "REF = %f %f %f %f %f %f %f %f\n"
+             "OUT = %f %f %f %f %f %f %f %f\n"
+             "TST =        %i        %i        %i        %i        %i        %i        %i        %i\n\n",
+           ptr[0].re, ptr[0].im, ptr[1].re, ptr[1].im,
+           ptr[2].re, ptr[2].im, ptr[3].re, ptr[3].im,
+           temp[0].re, temp[0].im, temp[1].re, temp[1].im,
+           temp[2].re, temp[2].im, temp[3].re, temp[3].im,
+           fabsf(ptr[0].re - temp[0].re) <= 2*FLT_EPSILON, fabsf(ptr[0].im - temp[0].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[1].re - temp[1].re) <= 2*FLT_EPSILON, fabsf(ptr[1].im - temp[1].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[2].re - temp[2].re) <= 2*FLT_EPSILON, fabsf(ptr[2].im - temp[2].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[3].re - temp[3].re) <= 2*FLT_EPSILON, fabsf(ptr[3].im - temp[3].im) <= 2*FLT_EPSILON);
+
+    out -= temp - orig;
+
+#endif
+
+    av_free(orig);
+}
+
+av_cold void ff_tx_init_double_aarch64(AVTXContext *s, av_tx_fn *tx)
+{
+    int cpu_flags = av_get_cpu_flags();
+    int gen_revtab = 0, basis, revtab_interleave;
+
+    if (s->flags & AV_TX_UNALIGNED)
+        return;
+
+#define TXFN(fn, gentab, sr_basis, interleave) \
+    do {                                       \
+        *tx = fn;                              \
+        gen_revtab = gentab;                   \
+        basis = sr_basis;                      \
+        revtab_interleave = interleave;        \
+    } while (0)
+
+    if (s->n == 1) {
+        if (have_neon(cpu_flags))
+            TXFN(ff_fft8_double_neon, 1, 8, 0);
+    }
+
+    if (s->n == 1 && have_neon(cpu_flags))
+        TXFN(test_fft, 1, 8, 0);
+
+    if (gen_revtab)
+        ff_tx_gen_split_radix_parity_revtab(s->revtab, s->m, s->inv, basis,
+                                            revtab_interleave);
+#undef TXFN
+}
diff --git a/libavutil/aarch64/tx_double_neon.S b/libavutil/aarch64/tx_double_neon.S
new file mode 100644
index 0000000000..28dbadc77f
--- /dev/null
+++ b/libavutil/aarch64/tx_double_neon.S
@@ -0,0 +1,26 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "asm.S"
+
+function ff_fft8_double_neon, export=1
+
+    /* code goes here */
+
+    ret
+endfunc
diff --git a/libavutil/tx.c b/libavutil/tx.c
index 1161df3285..329263b607 100644
--- a/libavutil/tx.c
+++ b/libavutil/tx.c
@@ -143,6 +143,61 @@ int ff_tx_gen_ptwo_inplace_revtab_idx(AVTXContext *s)
     return 0;
 }
 
+static void parity_revtab_generator(int *revtab, int n, int inv, int offset,
+                                    int is_dual, int dual_high, int len,
+                                    int basis, int dual_stride)
+{
+    len >>= 1;
+
+    if (len <= basis) {
+        int k1, k2, *even, *odd, stride;
+
+        is_dual = is_dual && dual_stride;
+        dual_high = is_dual & dual_high;
+        stride = is_dual ? FFMIN(dual_stride, len) : 0;
+
+        even = &revtab[offset + dual_high*(stride - 2*len)];
+        odd  = &even[len + (is_dual && !dual_high)*len + dual_high*len];
+
+#if 1
+        printf("At %i tx %i dual %i high %i even %li odd %li stride %i\n",
+               offset, len*2, is_dual, dual_high,
+               even - revtab, odd - revtab, stride);
+#endif
+
+        for (int i = 0; i < len; i++) {
+            k1 = -split_radix_permutation(offset + i*2 + 0, n, inv) & (n - 1);
+            k2 = -split_radix_permutation(offset + i*2 + 1, n, inv) & (n - 1);
+            *even++ = k1;
+            *odd++  = k2;
+            if (stride && !((i + 1) % stride)) {
+                even += stride;
+                odd  += stride;
+            }
+        }
+
+        return;
+    }
+
+    parity_revtab_generator(revtab, n, inv, offset,
+                            0, 0, len >> 0, basis, dual_stride);
+    parity_revtab_generator(revtab, n, inv, offset + (len >> 0),
+                            1, 0, len >> 1, basis, dual_stride);
+    parity_revtab_generator(revtab, n, inv, offset + (len >> 0) + (len >> 1),
+                            1, 1, len >> 1, basis, dual_stride);
+}
+
+void ff_tx_gen_split_radix_parity_revtab(int *revtab, int len, int inv,
+                                         int basis, int dual_stride)
+{
+    basis >>= 1;
+    if (len < basis)
+        return;
+    av_assert0(!dual_stride || !(dual_stride & (dual_stride - 1)));
+    av_assert0(dual_stride <= basis);
+    parity_revtab_generator(revtab, len, inv, 0, 0, 0, len, basis, dual_stride);
+}
+
 av_cold void av_tx_uninit(AVTXContext **ctx)
 {
     if (!(*ctx))
@@ -153,6 +208,7 @@ av_cold void av_tx_uninit(AVTXContext **ctx)
     av_free((*ctx)->revtab);
     av_free((*ctx)->inplace_idx);
     av_free((*ctx)->tmp);
+    av_free((*ctx)->arch_priv);
 
     av_freep(ctx);
 }
@@ -175,6 +231,10 @@ av_cold int av_tx_init(AVTXContext **ctx, av_tx_fn *tx, enum AVTXType type,
     case AV_TX_DOUBLE_MDCT:
         if ((err = ff_tx_init_mdct_fft_double(s, tx, type, inv, len, scale, flags)))
             goto fail;
+        if (ARCH_X86)
+           ff_tx_init_double_x86(s, tx);
+        if (ARCH_AARCH64)
+            ff_tx_init_double_aarch64(s, tx);
         break;
     case AV_TX_INT32_FFT:
     case AV_TX_INT32_MDCT:
diff --git a/libavutil/tx.h b/libavutil/tx.h
index bfc0c7f2a3..728e31aec7 100644
--- a/libavutil/tx.h
+++ b/libavutil/tx.h
@@ -93,7 +93,7 @@ enum AVTXType {
  * @param stride the input or output stride in bytes
  *
  * The out and in arrays must be aligned to the maximum required by the CPU
- * architecture.
+ * architecture unless the AV_TX_UNALIGNED flag was set in av_tx_init().
  * The stride must follow the constraints the transform type has specified.
  */
 typedef void (*av_tx_fn)(AVTXContext *s, void *out, void *in, ptrdiff_t stride);
@@ -108,6 +108,12 @@ enum AVTXFlags {
      * transform types.
      */
     AV_TX_INPLACE = 1ULL << 0,
+
+    /**
+     * Relaxes alignment requirement for the in and out arrays of av_tx_fn().
+     * May be slower with certain transform types.
+     */
+    AV_TX_UNALIGNED = 1ULL << 1,
 };
 
 /**
diff --git a/libavutil/tx_priv.h b/libavutil/tx_priv.h
index e2f4314a4f..4bc5f8579b 100644
--- a/libavutil/tx_priv.h
+++ b/libavutil/tx_priv.h
@@ -101,8 +101,8 @@ typedef void FFTComplex;
 #define CMUL3(c, a, b)                                                         \
     CMUL((c).re, (c).im, (a).re, (a).im, (b).re, (b).im)
 
-#define COSTABLE(size) \
-    DECLARE_ALIGNED(32, FFTSample, TX_NAME(ff_cos_##size))[size/2]
+#define COSTABLE(size)                                                         \
+    DECLARE_ALIGNED(32, FFTSample, TX_NAME(ff_cos_##size))[size/4 + 1]
 
 /* Used by asm, reorder with care */
 struct AVTXContext {
@@ -114,10 +114,12 @@ struct AVTXContext {
     double scale;       /* Scale */
 
     FFTComplex *exptab; /* MDCT exptab */
-    FFTComplex *tmp;    /* Temporary buffer needed for all compound transforms */
+    FFTComplex    *tmp; /* Temporary buffer needed for all compound transforms */
     int        *pfatab; /* Input/Output mapping for compound transforms */
     int        *revtab; /* Input mapping for power of two transforms */
     int   *inplace_idx; /* Required indices to revtab for in-place transforms */
+
+    void    *arch_priv; /* Arch-specific private data, will be av_free()'d on exit */
 };
 
 /* Shared functions */
@@ -142,6 +144,37 @@ static inline int split_radix_permutation(int i, int n, int inverse)
         return split_radix_permutation(i, m, inverse)*4 - 1;
 }
 
+/*
+ * This generates a parity-based revtab of length len and direction inv.
+ *
+ * Parity means even and odd complex numbers will be split, e.g. the even
+ * coefficients will come first, after which the odd coefficients will be
+ * placed. For example, a 4-point transform's coefficients after reordering:
+ * z[0].re, z[0].im, z[2].re, z[2].im, z[1].re, z[1].im, z[3].re, z[3].im
+ *
+ * The basis argument is the length of the largest non-composite transform
+ * supported, and also implies that the basis/2 transform is supported as well,
+ * as the split-radix algorithm requires it to be.
+ *
+ * The dual_stride argument indicates that both the basis, as well as the
+ * basis/2 transforms support doing two transforms at once, and the coefficients
+ * will be interleaved between each pair in a split-radix like so (stride == 2):
+ * tx1[0], tx1[2], tx2[0], tx2[2], tx1[1], tx1[3], tx2[1], tx2[3]
+ * A non-zero number switches this on, with the value indicating the stride
+ * (how many values of 1 transform to put first before switching to the other).
+ * Must be a power of two or 0. Must be less than the basis.
+ * Value will be clipped to the transform size, so for a basis of 16 and a
+ * dual_stride of 8, dual 8-point transforms will be laid out as if dual_stride
+ * was set to 4.
+ * Usually you'll set this to half the complex numbers that fit in a single
+ * register or 0. This allows to reuse SSE3 functions as dual-transform
+ * functions in AVX mode.
+ *
+ * If length is smaller than basis/2 this function will not do anything.
+ */
+void ff_tx_gen_split_radix_parity_revtab(int *revtab, int len, int inv,
+                                         int basis, int dual_stride);
+
 /* Templated functions */
 int ff_tx_init_mdct_fft_float(AVTXContext *s, av_tx_fn *tx,
                               enum AVTXType type, int inv, int len,
@@ -158,4 +191,7 @@ typedef struct CosTabsInitOnce {
     AVOnce control;
 } CosTabsInitOnce;
 
+void ff_tx_init_double_x86(AVTXContext *s, av_tx_fn *tx);
+void ff_tx_init_double_aarch64(AVTXContext *s, av_tx_fn *tx);
+
 #endif /* AVUTIL_TX_PRIV_H */
diff --git a/libavutil/tx_template.c b/libavutil/tx_template.c
index a436f426d2..f50c2c21dc 100644
--- a/libavutil/tx_template.c
+++ b/libavutil/tx_template.c
@@ -65,10 +65,11 @@ static av_always_inline void init_cos_tabs_idx(int index)
     int m = 1 << index;
     double freq = 2*M_PI/m;
     FFTSample *tab = cos_tabs[index];
-    for(int i = 0; i <= m/4; i++)
-        tab[i] = RESCALE(cos(i*freq));
-    for(int i = 1; i < m/4; i++)
-        tab[m/2 - i] = tab[i];
+
+    for (int i = 0; i < m/4; i++)
+        *tab++ = RESCALE(cos(i*freq));
+
+    *tab = 0;
 }
 
 #define INIT_FF_COS_TABS_FUNC(index, size)                                     \
diff --git a/libavutil/x86/Makefile b/libavutil/x86/Makefile
index 5f5242b5bd..f9fdbb1111 100644
--- a/libavutil/x86/Makefile
+++ b/libavutil/x86/Makefile
@@ -3,6 +3,7 @@ OBJS += x86/cpu.o                                                       \
         x86/float_dsp_init.o                                            \
         x86/imgutils_init.o                                             \
         x86/lls_init.o                                                  \
+        x86/tx_double_init.o                                            \
 
 OBJS-$(CONFIG_PIXELUTILS) += x86/pixelutils_init.o                      \
 
@@ -14,5 +15,6 @@ X86ASM-OBJS += x86/cpuid.o                                              \
              x86/float_dsp.o                                            \
              x86/imgutils.o                                             \
              x86/lls.o                                                  \
+             x86/tx_double.o                                            \
 
 X86ASM-OBJS-$(CONFIG_PIXELUTILS) += x86/pixelutils.o                    \
diff --git a/libavutil/x86/tx_double.asm b/libavutil/x86/tx_double.asm
new file mode 100644
index 0000000000..c8a5089e09
--- /dev/null
+++ b/libavutil/x86/tx_double.asm
@@ -0,0 +1,60 @@
+;******************************************************************************
+;* This file is part of FFmpeg.
+;*
+;* FFmpeg is free software; you can redistribute it and/or
+;* modify it under the terms of the GNU Lesser General Public
+;* License as published by the Free Software Foundation; either
+;* version 2.1 of the License, or (at your option) any later version.
+;*
+;* FFmpeg is distributed in the hope that it will be useful,
+;* but WITHOUT ANY WARRANTY; without even the implied warranty of
+;* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+;* Lesser General Public License for more details.
+;*
+;* You should have received a copy of the GNU Lesser General Public
+;* License along with FFmpeg; if not, write to the Free Software
+;* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+;******************************************************************************
+
+%include "x86util.asm"
+
+%if ARCH_X86_64
+%define ptr resq
+%else
+%define ptr resd
+%endif
+
+%assign i 16
+%rep 14
+cextern cos_ %+ i %+ _double ; ff_cos_i_double...
+%assign i (i << 1)
+%endrep
+
+struc AVTXContext
+    .n:           resd 1 ; Non-power-of-two part
+    .m:           resd 1 ; Power-of-two part
+    .inv:         resd 1 ; Is inverse
+    .type:        resd 1 ; Type
+    .flags:       resq 1 ; Flags
+    .scale:       resq 1 ; Scale
+
+    .exptab:       ptr 1 ; MDCT exptab
+    .tmp:          ptr 1 ; Temporary buffer needed for all compound transforms
+    .pfatab:       ptr 1 ; Input/Output mapping for compound transforms
+    .revtab:       ptr 1 ; Input mapping for power of two transforms
+    .inplace_idx:  ptr 1 ; Required indices to revtab for in-place transforms
+
+    .arch_priv:    ptr 1 ; Arch-specific private data, will be av_free()'d on exit
+endstruc
+
+SECTION_RODATA 32
+
+SECTION .text
+
+INIT_YMM avx
+cglobal fft8_double, 4, 4, 6, lut, out, in, tmp
+    mov lutq, [lutq + AVTXContext.revtab]
+
+    ; code goes here
+
+    RET
diff --git a/libavutil/x86/tx_double_init.c b/libavutil/x86/tx_double_init.c
new file mode 100644
index 0000000000..57a27d35c4
--- /dev/null
+++ b/libavutil/x86/tx_double_init.c
@@ -0,0 +1,198 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#define TX_DOUBLE
+#include "libavutil/tx_priv.h"
+#include "libavutil/x86/cpu.h"
+
+void ff_fft8_double_avx(AVTXContext *s, void *out, void *in, ptrdiff_t stride);
+
+
+#include <float.h>
+static void fft8(FFTComplex *z)
+{
+    FFTSample r1 = z[0].re - z[4].re;
+    FFTSample r2 = z[0].im - z[4].im;
+    FFTSample r3 = z[1].re - z[5].re;
+    FFTSample r4 = z[1].im - z[5].im;
+
+    FFTSample r5 = z[2].re - z[6].re;
+    FFTSample r6 = z[2].im - z[6].im;
+    FFTSample r7 = z[3].re - z[7].re;
+    FFTSample r8 = z[3].im - z[7].im;
+
+    FFTSample q1 = z[0].re + z[4].re;
+    FFTSample q2 = z[0].im + z[4].im;
+    FFTSample q3 = z[1].re + z[5].re;
+    FFTSample q4 = z[1].im + z[5].im;
+
+    FFTSample q5 = z[2].re + z[6].re;
+    FFTSample q6 = z[2].im + z[6].im;
+    FFTSample q7 = z[3].re + z[7].re;
+    FFTSample q8 = z[3].im + z[7].im;
+
+    FFTSample s3 = q1 - q3;
+    FFTSample s1 = q1 + q3;
+    FFTSample s4 = q2 - q4;
+    FFTSample s2 = q2 + q4;
+
+    FFTSample s7 = q5 - q7;
+    FFTSample s5 = q5 + q7;
+    FFTSample s8 = q6 - q8;
+    FFTSample s6 = q6 + q8;
+
+    FFTSample e1 = s1 * -1;
+    FFTSample e2 = s2 * -1;
+    FFTSample e3 = s3 * -1;
+    FFTSample e4 = s4 * -1;
+
+    FFTSample e5 = s5 *  1;
+    FFTSample e6 = s6 *  1;
+    FFTSample e7 = s7 * -1;
+    FFTSample e8 = s8 *  1;
+
+    FFTSample w1 =  e5 - e1;
+    FFTSample w2 =  e6 - e2;
+    FFTSample w3 =  e8 - e3;
+    FFTSample w4 =  e7 - e4;
+
+    FFTSample w5 =  s1 - e5;
+    FFTSample w6 =  s2 - e6;
+    FFTSample w7 =  s3 - e8;
+    FFTSample w8 =  s4 - e7;
+
+    z[0].re = w1;
+    z[0].im = w2;
+    z[2].re = w3;
+    z[2].im = w4;
+    z[4].re = w5;
+    z[4].im = w6;
+    z[6].re = w7;
+    z[6].im = w8;
+
+    FFTSample z1 = r1 - r4;
+    FFTSample z2 = r1 + r4;
+    FFTSample z3 = r3 - r2;
+    FFTSample z4 = r3 + r2;
+
+    FFTSample z5 = r5 - r6;
+    FFTSample z6 = r5 + r6;
+    FFTSample z7 = r7 - r8;
+    FFTSample z8 = r7 + r8;
+
+    z3 *= -1;
+    z5 *= -M_SQRT1_2;
+    z6 *= -M_SQRT1_2;
+    z7 *=  M_SQRT1_2;
+    z8 *=  M_SQRT1_2;
+
+    FFTSample t5 = z7 - z6;
+    FFTSample t6 = z8 + z5;
+    FFTSample t7 = z8 - z5;
+    FFTSample t8 = z7 + z6;
+
+    FFTSample u1 =  z2 + t5;
+    FFTSample u2 =  z3 + t6;
+    FFTSample u3 =  z1 - t7;
+    FFTSample u4 =  z4 + t8;
+
+    FFTSample u5 =  z2 - t5;
+    FFTSample u6 =  z3 - t6;
+    FFTSample u7 =  z1 + t7;
+    FFTSample u8 =  z4 - t8;
+
+    z[1].re = u1;
+    z[1].im = u2;
+    z[3].re = u3;
+    z[3].im = u4;
+    z[5].re = u5;
+    z[5].im = u6;
+    z[7].re = u7;
+    z[7].im = u8;
+}
+
+static av_unused void test_fft(AVTXContext *s, void *_out, void *_in,
+                               ptrdiff_t stride)
+{
+    FFTComplex *in = _in;
+    FFTComplex *out = _out;
+
+    FFTComplex *temp = av_malloc(2 * s->m * sizeof(FFTComplex)), *orig = temp;
+    for (int i = 0; i < s->m; i++) {
+        temp[i] = in[i];
+        out[i] = in[s->revtab[i]];
+    }
+
+    fft8(out);
+
+    ff_fft8_double_avx(s, temp, temp, stride);
+
+#if 1
+    temp += 0; out += temp - orig;
+
+    FFTComplex *ptr = (void *)out;
+
+    printf("\nIDX =      0re      0im      1re      1im      2re      2im      3re      3im\n"
+             "REF = %f %f %f %f %f %f %f %f\n"
+             "OUT = %f %f %f %f %f %f %f %f\n"
+             "TST =        %i        %i        %i        %i        %i        %i        %i        %i\n\n",
+           ptr[0].re, ptr[0].im, ptr[1].re, ptr[1].im,
+           ptr[2].re, ptr[2].im, ptr[3].re, ptr[3].im,
+           temp[0].re, temp[0].im, temp[1].re, temp[1].im,
+           temp[2].re, temp[2].im, temp[3].re, temp[3].im,
+           fabsf(ptr[0].re - temp[0].re) <= 2*FLT_EPSILON, fabsf(ptr[0].im - temp[0].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[1].re - temp[1].re) <= 2*FLT_EPSILON, fabsf(ptr[1].im - temp[1].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[2].re - temp[2].re) <= 2*FLT_EPSILON, fabsf(ptr[2].im - temp[2].im) <= 2*FLT_EPSILON,
+           fabsf(ptr[3].re - temp[3].re) <= 2*FLT_EPSILON, fabsf(ptr[3].im - temp[3].im) <= 2*FLT_EPSILON);
+
+    out -= temp - orig;
+
+#endif
+
+    av_free(orig);
+}
+
+av_cold void ff_tx_init_double_x86(AVTXContext *s, av_tx_fn *tx)
+{
+    int cpu_flags = av_get_cpu_flags();
+    int gen_revtab = 0, basis, revtab_interleave;
+
+    if (s->flags & AV_TX_UNALIGNED)
+        return;
+
+#define TXFN(fn, gentab, sr_basis, interleave) \
+    do {                                       \
+        *tx = fn;                              \
+        gen_revtab = gentab;                   \
+        basis = sr_basis;                      \
+        revtab_interleave = interleave;        \
+    } while (0)
+
+    if (s->n == 1) {
+        if (EXTERNAL_AVX_FAST(cpu_flags))
+            TXFN(ff_fft8_double_avx, 1, 8, 0);
+    }
+
+    if (s->n == 1 && EXTERNAL_AVX_FAST(cpu_flags))
+        TXFN(test_fft, 1, 8, 0);
+
+    if (gen_revtab)
+        ff_tx_gen_split_radix_parity_revtab(s->revtab, s->m, s->inv, basis,
+                                            revtab_interleave);
+#undef TXFN
+}
-- 
2.31.0.291.g576ba9dcdaf

